# 画像生成サブシステム仕様書

## システム概要

Note記事用ヘッダー画像を生成するためのサブシステム。

| 項目 | 値 |
|:---|:---|
| 推奨サイズ | 1280x670px (1.91:1) |
| フォーマット | PNG / WebP |
| 生成方式 | AI生成 or 合成 |

---

## モデル選択ガイド

> [!CAUTION]
> **Z-Image-TurboはZImagePipelineという独自パイプラインを使用。**
> `diffusers`の標準`AutoPipelineForText2Image`では動作しません。

| モデル | System RAM | VRAM | 特徴 |
|:---|:---|:---|:---|
| **Animagine XL 3.1** | 16GB | 8GB+ | アニメ調、SDXL系、標準パイプライン |
| **Z-Image-Turbo** | 16GB | 6-12GB | 6Bパラメータ、高速（8ステップ）、**要ZImagePipeline** |
| SDXL-Turbo | 16GB | 8GB+ | 高速生成（品質やや低） |

### Z-Image-Turbo 使用時の注意
- **パイプライン**: `ZImagePipeline`（diffusers 0.36.0+）
- **テキストエンコーダ**: Qwen2Tokenizer
- **VRAM**: 6-12GB（fp16使用時）
- **推論ステップ**: 8（デフォルト）

---

## モデル設定

### Animagine XL 3.1（16GB RAM環境向け）

`scripts/generate_image_local.py` を以下のように変更:

```python
MODEL_PATH = "cagliostrolab/animagine-xl-3.1"
```

または `config.yaml`:
```yaml
image:
  model: "cagliostrolab/animagine-xl-3.1"
  device: "cuda"
  width: 1024
  height: 1024
  num_inference_steps: 28
  guidance_scale: 7.0
```

### Z-Image-Turbo

> [!WARNING]
> `AutoPipelineForText2Image`を使用するとCPUオフロードが発生しOOMになる可能性あり。
> 正しくは`ZImagePipeline`を直接使用する。

```python
from diffusers import ZImagePipeline

pipe = ZImagePipeline.from_pretrained(
    "Tongyi-MAI/Z-Image-Turbo",
    torch_dtype=torch.float16  # 必須: FP32だとRAM/VRAM倍増
)
pipe.to("cuda")
```

---

## 依存ライブラリ

```bash
uv pip install diffusers transformers accelerate torch pillow
```

---

## スクリプト

### AI画像生成
`scripts/generate_image_local.py`

```bash
uv run python scripts/generate_image_local.py \
  "プロンプト" \
  output.png \
  --width 768 \
  --height 402
```

### 合成画像
`scripts/create_composite_header.py`

```bash
uv run python scripts/create_composite_header.py \
  --output articles/note_images/003.png \
  frontend/public/assets/games/game1.webp \
  frontend/public/assets/games/game2.webp
```

---

## プロンプトテンプレート

```
(masterpiece), (best quality), (very aesthetic), (absurdres),
{ユーザープロンプト},
(rating:safe)
```

### ネガティブプロンプト
```
(worst quality, low quality:1.4), (grayscale), nsfw
```

---

## トラブルシューティング

### Exit 137 の原因

Exit 137 = **SIGKILL** = **System RAM不足** (OOM killer)

> [!IMPORTANT]
> VRAM不足では Exit 137 にならない。VRAM不足時は `CUDA out of memory` エラー。

### OOM発生時のチェックリスト

1. **`torch_dtype=torch.float16`を指定しているか？**
   - FP32だとモデルサイズが2倍になる
2. **正しいパイプラインクラスを使用しているか？**
   - Z-Image-Turbo → `ZImagePipeline`
   - Animagine XL 3.1 → `AutoPipelineForText2Image`
3. **CPUオフロードが誤って有効になっていないか？**
   - `enable_sequential_cpu_offload()`はRAMを大量消費する

### 診断コマンド

```bash
# GPU認識確認
nvidia-smi

# PyTorch CUDA確認
uv run python -c "import torch; print(torch.cuda.is_available())"

# VRAM監視
watch -n 0.5 nvidia-smi

# System RAM監視
free -h

# OOM killer確認
dmesg -T | tail -n 50
```

### 症状別対策

| 症状 | 原因 | 対策 |
|:---|:---|:---|
| Exit 137 | System RAM不足 | **Animagine XL 3.1に切替** |
| CUDA out of memory | VRAM不足 | 解像度縮小 |
| nvidia-smiでVRAM増えない | GPU未使用 | CUDA/ドライバ確認 |
